---
  title: "Understanding Model Convergence"
author: "Brice Green"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
  toc: true
vignette: >
  %\VignetteIndexEntry{baggr_model_convergence}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: baggr.bib
---

The `baggr` package makes running Bayesian meta-analysis models very easy, but that ease can also obscure some things that go on behind the scenes. Especially with low-data settings, say with only a few measurements, you may get cryptic error messages when you run your models, like

```
Warning: There were 110 divergent transitions after warmup. Increasing adapt_delta above 0.9 may help. See
http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup
```

This vignette will walk through the basic intuition for what those mean, whether to be concerned about them, and how to tune the parameters underneath the hood. There are already a number of good resources that go more in depth on the topic so first I'll point you there:

[Visual MCMC Diagnostics Using the Bayesplot Package](https://mc-stan.org/bayesplot/articles/visual-mcmc-diagnostics.html)

[Scale Reduction in the Stan Manual](https://mc-stan.org/docs/2_21/reference-manual/notation-for-samples-chains-and-draws.html)

[Divergent Transitions in the Stan Manual](https://mc-stan.org/docs/2_21/reference-manual/divergent-transitions.html)

These go more in depth than this discussion is going to, but if you find yourself needing a stronger treatment of the topics then these would be good starting points.

# Behind the scenes: basics of MCMC

The baggr package uses fully Bayesian methods to estimate meta-analysis models, meaning that it takes a prior (which if not specified by the user is assigned by default), and jointly with the data uses that prior to estimate a posterior according to Bayes' rule


$$P(\theta | X) = \dfrac{P(X | \theta) P(\theta)}{P(X)}$$

In order to calculate $P(X)$, we need some computationally expensive machinery that can calculate

$$P(X) = \int P(X | \theta) d\theta $$

which is (in general) really difficult except for a few specific situations. In order to make these types of models easy to run, we use a method that approximates this integral to a high degree of numerical accuracy.

MCMC methods leverage an accept/reject proposal scheme by generating a potential value for $\theta$, which is some set of parmeters, and using the relative likelihoods ($P(\theta|X)$) at that new value to determine the probability of whether to accept or reject those proposals. The simplest of these methods, Metropolis-Hastings, pretty much ends there. But for meta-analysis models (and other models with of high dimension), the spaces that the random walk has to explore get really complicated.

So instead of plain-old Metropolis-Hastings, we use Hamiltonian Monte Carlo with No-U-Turn sampling, powered on the back end by Stan. This algorithm leverages the gradient, or the rate of change in the posterior density at a given parameter value, in order to more efficiently generate new parameter proposals.

# Warnings like "divergent transitions"

The gradient is passed into a Hamiltonian equation, which simulates a path for where it thinks the posterior is headed. But this trajectory is based on the local behavior of the posterior, and depending on the geometry, if we move too far away from that point we might get more and more off base. Stan, on the back end, uses the `adapt_delta` parameter to determine how often it needs to check its simulated paths, re-evaluating the trajectory it is using.

If you make `adapt_delta` really big, you end up moving really slowly, but you also are less likely to fly off the true trajectory of the posterior distribution. But if you make it small, you go faster, etc. You get the idea. How high you should set the parameter depends on the extent to which the algorithm is properly modeling the paths. So if you encounter divergent transitions, it is often good to raise `adapt_delta`. This discussion is really oversimplifying things to build the intuition, but you can find an (accessible) deeper discussion [here](https://arxiv.org/abs/1701.02434)
if it is of interest!

When you get a warning that there are a certain number of "divergent transitions," it means that the samples have gone far away from the anticipated path, and (at worse) are reduced to a random walk. This means that they may not be fully exploring the posterior distribution, and so you may need more iterations to get a good approximation of the distribution.

If you get this warning and want to re-estimate your model with a higher `adapt_delta` setting, you can change the argument in the call to the `baggr` function like so:

```{r}
# the ... parameters in the call to baggr() are
# passed to rstan::sampling
# for documentation see ?rstan::sampling
fit <- baggr(schools, model = "rubin",
      pooling = "partial",
      refresh = 0, # silence printing MCMC draws
      prior_hypermean = normal(0, 10),
      prior_hypersd = cauchy(0, 3),
      control = list(
        adapt_delta = 0.9 # 0.8 by default
      ))

fit
```

If you still get a lot of divergent transitions after raising the `adapt_delta` really high, it may indicate an issue with your model! This is what is commonly referred to as the [folk theorem of statistical computing](https://statmodeling.stat.columbia.edu/2008/05/13/the_folk_theore/).

# $\widehat{R}$ being too low

The other warning you get, that “r hat” statistics are too high, indicates that the effective sample size (ESS) of your draws are too low and your chains have not converged. Because MCMC is not a deterministic algorithm, we run multiple chains of samples in order to check that each has converged to a good enough answer.

We want to check that each chain is “mixing well,” meaning that we have enough effective draws after accounting for the correlation between samples. We also want to check that markov chains initialized at different values get to similar places. ESS gives us a measure of the first, and $\widehat{R}$ gives a measure of the second.

If you have a low ESS or high $\widehat{R}$, you are best off running each chain for more iterations until you get a higher ESS/lower $\widehat{R}$. To run chains for longer, you change the `iter` parameter in the `...` arguments to your `baggr()` call.

```{r}
# runs for 10,000 iterations per chain instead of 2,000
fit <- baggr(schools, model = "rubin", pooling = "partial",
      prior_hypermean = normal(0,1), prior_hypersd = cauchy(0,2),
      refresh = 0, # don't print sampling
      iter = 10000, 
      control = list(
        adapt_delta = 0.95 # like above, to address divergences
      ))

fit
```

# Hitting maximum treedepth

Sometimes you get warnings about hitting "maximum treedepth." This is less of an issue than the previous two warnings, which fundamentally throw the resulting infrence into question. Stan uses a binary tree to determine how many "leapfrog steps" to take at each iteration of the sampler. This has to do with the way in which the sampler approximates movement through the Hamiltonian system used to model the posterior. Basically, you need to figure out how far away you want to jump from your current sample draw (this is how we end up getting more efficient exploration of the space). In order to do that, Stan evaluates a "tree," which is basically a proposal equally spaced on either side of the current draw. Then it does this again at each of the two points that are drawn, and so on, until it meets a certain criteria for accepting the new value. The `max_treedepth` parameter controls how deeply the algorithm should search (how many sub-trees to create) before terminating.

Hitting the maximum treedepth may be indicative of a deeper issue with the model, but if you are confident in your model and your data, you should increase the `max_treedepth` parameter that is passed to the `control` list that `rstan::sampling` uses.

```{r}

# runs for 10,000 iterations per chain instead of 2,000
fit <- baggr(schools, model = "rubin", pooling = "partial",
      prior_hypermean = normal(0,1), prior_hypersd = cauchy(0,2),
      refresh = 0, # don't print sampling
      iter = 10000, 
      control = list(
        adapt_delta = 0.95, # like above, to address divergences
        max_treedepth = 20 # manually setting maximum tree depth
      ))

fit
```

