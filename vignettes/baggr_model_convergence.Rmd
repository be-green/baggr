---
title: "Understanding Model Convergence"
author: "Brice Green"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
  toc: true
vignette: >
  %\VignetteIndexEntry{baggr}
%\VignetteEngine{knitr::rmarkdown}
%\VignetteEncoding{UTF-8}
bibliography: baggr.bib
---

The `baggr` package makes running Bayesian meta-analysis models very easy, but that ease can also obscure some things that go on behind the scenes. Especially with low-data settings, say with only a few measurements, you may get cryptic error messages when you run your models, like

```
Warning: There were 110 divergent transitions after warmup. Increasing adapt_delta above 0.9 may help. See
http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup
```

This vignette will walk through the basic intuition for what those mean, whether to be concerned about them, and how to tune the parameters underneath the hood. There are already a number of good resources that go more in depth on the topic so first I'll point you there:

[Visual MCMC Diagnostics Using the Bayesplot Package](https://mc-stan.org/bayesplot/articles/visual-mcmc-diagnostics.html)

[Scale Reduction in the Stan Manual](https://mc-stan.org/docs/2_21/reference-manual/notation-for-samples-chains-and-draws.html)

[Divergent Transitions in the Stan Manual](https://mc-stan.org/docs/2_21/reference-manual/divergent-transitions.html)

These go more in depth than this discussion is going to, but if you find yourself needing a deeper discussion then these would be good starting points.

# Behind the scenes: basics of MCMC

The baggr package uses fully Bayesian methods to estimate meta-analysis models, meaning that it takes a prior (which if not specified is assigned by default), and jointly with the data uses that prior to estimate a posterior according to Bayes' rule


$$P(\theta | X) = \dfrac{P(X | \theta) P(\theta)}{P(X)}$$

In order to calculate $P(X)$, we need some computationally expensive machinery that can calculate

$$P(X) = \int P(X | \theta) d\theta $$

which is (in general) really difficult except for a few specific situations. In order to make these types of models easy to run, we use a method that approximates this integral to a high degree of numerical accuracy.

MCMC methods leverage an accept/reject proposal scheme by generating a potential value for $\theta$, which is some set of parmeters, and using the relative likelihoods ($P(\theta|X)$) at that new value to determine the probability of whether to accept or reject those proposals. The simplest of these methods, Metropolis-Hastings, pretty much ends there. But for meta-analysis models (and other models with of high dimension), the spaces that the random walk has to explore get really complicated.

So instead of plain-old Metropolis-Hastings, we use Hamiltonian Monte Carlo with No-U-Turn sampling, powered on the back end by Stan. This algorithm leverages the gradient, or the rate of change in the posterior density at a given parameter value, in order to more efficiently generate new parameter proposals.

# Warnings like "divergent transitions"

The gradient is passed into a Hamiltonian equation, which simulates a path for where it thinks the posterior is headed. But this trajectory is based on the local behavior of the posterior, and depending on the geometry, if we move too far away from that point we might get more and more off base. Stan, on the back end, uses the `adapt_delta` parameter to determine how often it needs to check its simulated paths, re-evaluating the trajectory it is using. 

If you make `adapt_delta` really big, you end up moving really slowly, but you also are less likely to fly off the true trajectory of the posterior distribution. But if you make it small, you go faster, etc. You get the idea. How high you should set the parameter depends on the extent to which the algorithm is properly modeling the paths. So if you encounter divergent transitions, it is often good to raise `adapt_delta`. This discussion is really oversimplifying things to build the intuition, but you can find an (accessible) deeper discussion [here](https://arxiv.org/abs/1701.02434)
if it is of interest!

When you get a warning that there are a certain number of "divergent transitions," it means that the samples have gone far away from the anticipated path, and (at worse) are reduced to a random walk. This means that they may not be fully exploring the posterior distribution, and so you may need more iterations to get a good approximation of the distribution.

If you get this warning and want to re-estimate your model with a higher `adapt_delta` setting, you can change the argument in the call to the `baggr` function like so:

```{r}
# the ... parameters in the call to baggr() are
# passed to rstan::sampling
# for documentation see ?rstan::sampling

baggr(schools, model = "rubin", 
      pooling = "partial",
      prior_hypermean = normal(0, 10),
      prior_hypersd = cauchy(0, 3),
      control = list(
        adapt_delta = 0.9 # 0.8 by default
      ))
```

If you still get a lot of divergent transitions after raising the `adapt_delta` really high, it may indicate an issue with your model! This is what is commonly referred to as the [folk theorem of statistical computing](https://statmodeling.stat.columbia.edu/2008/05/13/the_folk_theore/).

# R hat being too low

The other warning you get, that r_hat statistics are too low, indicates that the 
